{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'SNEX'\n",
    "exchange = 'nsdq'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns and cleanup\n",
    "df = pd.read_csv(f'data/{ticker}-{exchange}.csv')\n",
    "df = df.drop([f'open {ticker} Price in USD', f'high {ticker} Price in USD',\n",
    "             f'low {ticker} Price in USD', 'Dividends', 'hidden'], axis=1)\n",
    "df = df.rename(columns={'Exchange Reported SI': 'SI',\n",
    "               f'close {ticker} Price in USD': 'Close', 'Days to cover 3m (on loan)': 'Days To Cover'})\n",
    "df = df.dropna(subset=['Close'])\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Close 2 week rolling'] = df['Close'].rolling(10).mean()\n",
    "df = df.set_index('Date')\n",
    "first_SI_index = df['SI'].first_valid_index()\n",
    "df = df.loc[first_SI_index:]\n",
    "df = df[:-1]\n",
    "df['index'] =np.arange(len(df))\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 10))\n",
    "ax3 = ax.twinx()\n",
    "# df['SI'].dropna().plot(ax=ax3, legend=True, linestyle='-', marker='.')\n",
    "df['Days To Cover'].dropna().plot(ax=ax3, legend=True)\n",
    "# df['Cost To Borrow'].dropna().plot(ax=ax3, legend=True)\n",
    "df['Close 2 week rolling'].plot(ax=ax, style='r-', legend=True)\n",
    "df['Close'].plot(ax=ax, style='g-', legend=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overallPearsonR(col):\n",
    "    dropped_df = df.dropna(subset=[col, 'Close'])\n",
    "    r, p = stats.pearsonr(dropped_df[col], dropped_df['Close'])\n",
    "    print(f'{col} against Close Pearson r: {r}, p-value: {p}')\n",
    "\n",
    "\n",
    "for col in ['SI', 'Days To Cover', 'Cost To Borrow']:\n",
    "    overallPearsonR(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_df = df.dropna(subset=['SI', 'Close 2 week rolling'])\n",
    "r, p = stats.pearsonr(dropped_df['SI'], dropped_df['Close 2 week rolling'])\n",
    "print(f'SI against 2 week rolling close Pearson r: {r}, p-value: {p}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local correlation\n",
    "df_interpolated = df.interpolate()\n",
    "df_interpolated.head()\n",
    "# window 40 = 2 months?\n",
    "rolling_r = df['Close'].rolling(40).corr(df_interpolated['SI'])\n",
    "fig, ax = plt.subplots(2,1,figsize=(25, 15))\n",
    "ax3 = ax[0].twinx()\n",
    "df['SI'].dropna().plot(ax=ax3,linestyle='-', marker='.').legend(loc='upper left')\n",
    "df['Close'].rolling(10).mean().plot(ax=ax[0], style='r-', legend=True)\n",
    "rolling_r.plot(ax=ax[1], xlim=ax[0].get_xlim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time lagged cross correlation\n",
    "def crosscorr(datax, datay, lag=0, wrap=False):\n",
    "    \"\"\" Lag-N cross correlation. \n",
    "    Shifted data filled with NaNs \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lag : int, default 0\n",
    "    datax, datay : pandas.Series objects of equal length\n",
    "    Returns\n",
    "    ----------\n",
    "    crosscorr : float\n",
    "    \"\"\"\n",
    "    if wrap:\n",
    "        shiftedy = datay.shift(lag)\n",
    "        shiftedy.iloc[:lag] = datay.iloc[-lag:].values\n",
    "        return datax.corr(shiftedy)\n",
    "    else:\n",
    "        return datax.corr(datay.shift(lag))\n",
    "\n",
    "\n",
    "d1 = df['Close']\n",
    "d2 = df_interpolated['SI']\n",
    "rs = [crosscorr(d1, d2, lag) for lag in range(-60, 60)]\n",
    "# use absolute value as could be positve or negatively correlated\n",
    "offset = np.floor(len(rs)/2)-np.argmax(np.abs(rs))\n",
    "print(rs[np.argmax(np.abs(rs))])\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "ax.plot(rs)\n",
    "ax.axvline(np.ceil(len(rs)/2), color='k', linestyle='--', label='Center')\n",
    "ax.axvline(np.argmax(np.abs(rs)), color='r', linestyle='--', label='Peak synchrony')\n",
    "ax.set(title=f'Offset = {offset}', xlabel='Offset', ylabel='Pearson r')\n",
    "ax.set_xticks([0, 20, 40, 60, 80, 100, 120])\n",
    "ax.set_xticklabels([-60, -40, -20, 0, 20, 40, 60])\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost To Borrow time lagged cross correlation\n",
    "d1 = df['Close']\n",
    "d2 = df_interpolated['Cost To Borrow']\n",
    "rs = [crosscorr(d1, d2, lag) for lag in range(-60, 60)]\n",
    "# use absolute value as could be positve or negatively correlated\n",
    "offset = np.floor(len(rs)/2)-np.argmax(np.abs(rs))\n",
    "print(rs[np.argmax(np.abs(rs))])\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "ax.plot(rs)\n",
    "ax.axvline(np.ceil(len(rs)/2), color='k', linestyle='--', label='Center')\n",
    "ax.axvline(np.argmax(np.abs(rs)), color='r', linestyle='--', label='Peak synchrony')\n",
    "ax.set(title=f'Offset = {offset}', xlabel='Offset', ylabel='Pearson r')\n",
    "ax.set_xticks([0, 20, 40, 60, 80, 100, 120])\n",
    "ax.set_xticklabels([-60, -40, -20, 0, 20, 40, 60])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "\n",
    "# Windowed time lagged cross correlation\n",
    "num_splits = 7\n",
    "samples_per_split = df.shape[0]/num_splits\n",
    "rss=[]\n",
    "for t in range(0, num_splits):\n",
    "    d1 = df['Close'].loc[(t)*samples_per_split:(t+1)*samples_per_split]\n",
    "    d2 = df['SI'].loc[(t)*samples_per_split:(t+1)*samples_per_split]\n",
    "    rs = [crosscorr(d1,d2, lag) for lag in range(-60,60)]\n",
    "    rss.append(rs)\n",
    "rss = pd.DataFrame(rss)\n",
    "f,ax = plt.subplots(figsize=(10,5))\n",
    "sns.heatmap(rss,cmap='RdBu_r',ax=ax)\n",
    "ax.set(title=f'Windowed Time Lagged Cross Correlation', xlabel='Offset',ylabel='Window epochs')\n",
    "ax.set_xticks([0, 20, 40, 60, 80, 100, 120])\n",
    "ax.set_xticklabels([-60, -40, -20, 0, 20, 40, 60])\n",
    "\n",
    "# set index back to date\n",
    "df = df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling window time lagged cross correlation\n",
    "window_size = 70 #samples\n",
    "t_start = 0\n",
    "t_end = t_start + window_size\n",
    "step_size = 20\n",
    "rss=[]\n",
    "while t_end < len(df):\n",
    "    d1 = df['Close'].iloc[t_start:t_end]\n",
    "    d2 = df['SI'].iloc[t_start:t_end]\n",
    "    rs = [crosscorr(d1,d2, lag, wrap=False) for lag in range(-60,60)]\n",
    "    rss.append(rs)\n",
    "    t_start = t_start + step_size\n",
    "    t_end = t_end + step_size\n",
    "rss = pd.DataFrame(rss)\n",
    "\n",
    "f,ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(rss,cmap='RdBu_r',ax=ax)\n",
    "ax.set(title=f'Rolling Windowed Time Lagged Cross Correlation', xlabel='Offset',ylabel='Epochs')\n",
    "ax.set_xticks([0, 20, 40, 60, 80, 100, 120])\n",
    "ax.set_xticklabels([-60, -40, -20, 0, 20, 40, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import hilbert, butter, filtfilt\n",
    "from scipy.fftpack import fft,fftfreq,rfft,irfft,ifft\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "lowcut  = .01\n",
    "highcut = .5\n",
    "fs = 30.\n",
    "order = 1\n",
    "d1 = df['Close'].interpolate().values\n",
    "d2 = df['SI'].interpolate().values\n",
    "y1 = butter_bandpass_filter(d1,lowcut=lowcut,highcut=highcut,fs=fs,order=order)\n",
    "y2 = butter_bandpass_filter(d2,lowcut=lowcut,highcut=highcut,fs=fs,order=order)\n",
    "\n",
    "al1 = np.angle(hilbert(y1),deg=False)\n",
    "al2 = np.angle(hilbert(y2),deg=False)\n",
    "phase_synchrony = 1-np.sin(np.abs(al1-al2)/2)\n",
    "N = len(al1)\n",
    "\n",
    "# Plot results\n",
    "f,ax = plt.subplots(3,1,figsize=(14,7),sharex=True)\n",
    "ax[0].plot(y1,color='r',label='y1')\n",
    "ax[0].plot(y2,color='b',label='y2')\n",
    "ax[0].legend(bbox_to_anchor=(0., 1.02, 1., .102),ncol=2)\n",
    "ax[0].set(xlim=[0,N], title='Filtered Timeseries Data')\n",
    "ax[1].plot(al1,color='r')\n",
    "ax[1].plot(al2,color='b')\n",
    "ax[1].set(ylabel='Angle',title='Angle at each Timepoint',xlim=[0,N])\n",
    "phase_synchrony = 1-np.sin(np.abs(al1-al2)/2)\n",
    "ax[2].plot(phase_synchrony)\n",
    "ax[2].set(ylim=[0,1.1],xlim=[0,N],title='Instantaneous Phase Synchrony',xlabel='Time',ylabel='Phase Synchrony')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average SI, DTC and annualised return\n",
    "avg_SI = df['SI'].mean()\n",
    "print(avg_SI)\n",
    "avg_DTC = df['Days To Cover'].mean()\n",
    "print(avg_DTC)\n",
    "ret_series = (1 + df['Close'].pct_change()).cumprod() - 1\n",
    "overall_return = ret_series.tail(1)[0]\n",
    "period_days = (df.tail(1).index.date - df.head(1).index.date)[0].days\n",
    "annualised_return = (1 + overall_return)**(365/period_days) - 1\n",
    "print(annualised_return)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add csv file into data folder and run code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats_df = pd.DataFrame(columns=['SI Pearson r', 'SI p-value (r)', 'SI offset', 'SI Corr at offset', 'DTC Pearson r',\n",
    "#                         'DTC p-value (r)', 'DTC offset', 'DTC Corr at offset', 'CTB Pearson r', 'CTB p-value (r)', 'CTB offset', 'CTB Corr at offset', 'Avg SI', 'Avg DTC', 'Annualised return'])\n",
    "# stats_df.index.name = 'ticker'\n",
    "\n",
    "stats_df = pd.read_csv('stats.csv', index_col='ticker')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correl(csv_file):\n",
    "    [ticker, exchange] = csv_file[:-4].split('-')\n",
    "    if f'{ticker}_{exchange}' in stats_df.index:\n",
    "        return\n",
    "    df = pd.read_csv(f'data/{ticker}-{exchange}.csv')\n",
    "    df = df.drop([f'open {ticker} Price in USD', f'high {ticker} Price in USD',\n",
    "                  f'low {ticker} Price in USD', 'Dividends', 'hidden'], axis=1)\n",
    "    df = df.rename(columns={'Exchange Reported SI': 'SI',\n",
    "                            f'close {ticker} Price in USD': 'Close', 'Days to cover 3m (on loan)': 'Days To Cover'})\n",
    "    df = df.dropna(subset=['Close'])\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Close 2 week rolling'] = df['Close'].rolling(10).mean()\n",
    "    df = df.set_index('Date')\n",
    "    first_SI_index = df['SI'].first_valid_index()\n",
    "    df = df.loc[first_SI_index:]\n",
    "    if len(df) < 10:\n",
    "        print(csv_file)\n",
    "        return\n",
    "    df = df[:-1]\n",
    "    df['index'] = np.arange(len(df))\n",
    "\n",
    "    df_interpolated = df.interpolate()\n",
    "\n",
    "    dropped_df = df.dropna(subset=['SI', 'Close'])\n",
    "    if len(dropped_df) < 10:\n",
    "        print(csv_file)\n",
    "        return\n",
    "    r, p = stats.pearsonr(dropped_df['SI'], dropped_df['Close'])\n",
    "\n",
    "    dropped_df = df.dropna(subset=['Cost To Borrow', 'Close'])\n",
    "    if len(dropped_df) < 10:\n",
    "        print(csv_file)\n",
    "        return\n",
    "    ctb_r, ctb_p = stats.pearsonr(\n",
    "        dropped_df['Cost To Borrow'], dropped_df['Close'])\n",
    "\n",
    "    dropped_df = df.dropna(subset=['Days To Cover', 'Close'])\n",
    "    if len(dropped_df) < 10:\n",
    "        print(csv_file)\n",
    "        return\n",
    "    dtc_r, dtc_p = stats.pearsonr(\n",
    "        dropped_df['Days To Cover'], dropped_df['Close'])\n",
    "\n",
    "    def crosscorr(datax, datay, lag=0, wrap=False):\n",
    "        \"\"\" Lag-N cross correlation. \n",
    "        Shifted data filled with NaNs \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        lag : int, default 0\n",
    "        datax, datay : pandas.Series objects of equal length\n",
    "        Returns\n",
    "        ----------\n",
    "        crosscorr : float\n",
    "        \"\"\"\n",
    "        if wrap:\n",
    "            shiftedy = datay.shift(lag)\n",
    "            shiftedy.iloc[:lag] = datay.iloc[-lag:].values\n",
    "            return datax.corr(shiftedy)\n",
    "        else:\n",
    "            return datax.corr(datay.shift(lag))\n",
    "\n",
    "    d1 = df['Close']\n",
    "    d2 = df_interpolated['SI']\n",
    "    rs = [crosscorr(d1, d2, lag) for lag in range(-60, 60)]\n",
    "    si_offset = np.floor(len(rs)/2)-np.argmax(np.abs(rs))\n",
    "    si_max_corr = rs[np.argmax(np.abs(rs))]\n",
    "\n",
    "    d3 = df_interpolated['Days To Cover']\n",
    "    rs = [crosscorr(d1, d3, lag) for lag in range(-60, 60)]\n",
    "    dtc_offset = np.floor(len(rs)/2)-np.argmax(np.abs(rs))\n",
    "    dtc_max_corr = rs[np.argmax(np.abs(rs))]\n",
    "\n",
    "    d4 = df_interpolated['Cost To Borrow']\n",
    "    rs = [crosscorr(d1, d4, lag) for lag in range(-60, 60)]\n",
    "    ctb_offset = np.floor(len(rs)/2)-np.argmax(np.abs(rs))\n",
    "    ctb_max_corr = rs[np.argmax(np.abs(rs))]\n",
    "\n",
    "    avg_SI = df['SI'].mean()\n",
    "    avg_DTC = df['Days To Cover'].mean()\n",
    "    ret_series = (1 + df['Close'].pct_change()).cumprod() - 1\n",
    "    overall_return = ret_series.tail(1)[0]\n",
    "    period_days = (df.tail(1).index.date - df.head(1).index.date)[0].days\n",
    "    annualised_return = (1 + overall_return)**(365/period_days) - 1\n",
    "\n",
    "    stats_df.loc[f'{ticker}_{exchange}']['Annualised return'] = [r, p, si_offset, si_max_corr, dtc_r,\n",
    "                                            dtc_p, dtc_offset, dtc_max_corr, ctb_r, ctb_p, ctb_offset, ctb_max_corr,\n",
    "                                            avg_SI, avg_DTC, annualised_return]\n",
    "\n",
    "\n",
    "filenames = os.listdir('data')\n",
    "for file in filenames:\n",
    "    correl(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df.to_csv('stats.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6013e67b0afc9f5037c2c5a161d95c97e3822010f0e47dbe6c1004cdba192025"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
